# Deep-Learning-Nanodegree-Udacity
This Repo contains my journey taking the "Deep Learning Nanodegree" with Udacity

## Table Of Contents

### Tutorials

### Introduction to Neural Networks
* [Gradient Descent](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/2.Neural-Networks/L1.Introduction-to-neural-networks/gradient-descent): Implementing Gradient Descent.
* [Backpropagation](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/2.Neural-Networks/L1.Introduction-to-neural-networks/student-admissions): Implementing backpropagation step, scaling and one hot encoding to the data.
* [Gradient Descent with Mean Square Error](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/2.Neural-Networks/L2.Implementing-gradient-descent/gradient-descent-MeanSquareError): Implementing Gradient Descent with Mean Square Error.
* [Multilayer Perceptrons backpropagation](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/2.Neural-Networks/L2.Implementing-gradient-descent/Multilayer-Perceptrons-backpropagation): Implementing multi layer perceptrons backpropagation.
* [Sentiment Analysis with Numpy](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/2.Neural-Networks/L5.Sentiment%20Analysis/sentiment-analysis-network): [Andrew Trask](http://iamtrask.github.io/) leads you through building a sentiment analysis model, predicting if some text (films review) is positive or negative.
* [Deep Learning with PyTorch](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/2.Neural-Networks/L7.Deep-Learning-with-PyTorch/intro-to-pytorch): Introduction to deep learning with PyTorch.

### Convolutional Neural Networks
* [Convolutional Neural Networks](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/3.Convolutional-Neural-Networks/L1.Convolutional-Neural-Networks/convolutional-neural-networks): Visualize the output of layers that make up a CNN. Learn how to define and train a CNN for classifying MNIST data, a handwritten digit database that is notorious in the fields of machine and deep learning. Also, define and train a CNN for classifying images in the CIFAR10 dataset.
* [Transfer Learning (ConvNet)](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/3.Convolutional-Neural-Networks/L4.Transfer-Learning/transfer-learning). In practice, most people don't train their own large networkd on huge datasets, but use pretrained networks such as VGGnet. Here you'll use VGGnet to classify images of flowers without training a network on the images themselves.
* [Weight Intialization](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/3.Convolutional-Neural-Networks/L5.Weight-Initialization/weight-initialization): Explore how initializing network weights affects performance.
* [Autoencoders](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/3.Convolutional-Neural-Networks/L6.Auto-Encoders/autoencoder): Build models for image compression and denoising, using feed-forward and convolution networks in TensorFlow.
* [Style Transfer](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/3.Convolutional-Neural-Networks/L7.Style-Transfer/style-transfer): Use a pre-trained network to extract content and style features from an image.

### Recurrent Neural Networks
* [Intro to Recurrent Networks (Time-Series Prediction)](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/4.Recurrent-Neural-Networks/L3.Implementation-of-RNN-and-LSTM/time-series): Recurrent neural networks are able to use information about the sequence of data.
* [Intro to Recurrent Networks (Character-wise RNN)](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/4.Recurrent-Neural-Networks/L3.Implementation-of-RNN-and-LSTM/char-rnn): Recurrent neural networks are able to use information about the sequence of data, such as the sequence of characters in text.
* [Embeddings (Word2Vec)](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/4.Recurrent-Neural-Networks/L5.Embeddings-and-Word2Vec/word2vec-embeddings): Implement the Word2Vec model to find semantic representations of words for use in natural language processing.
* [Sentiment Analysis RNN](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/4.Recurrent-Neural-Networks/L6.Sentiment-Prediction-RNN/sentiment-rnn): Implement a recurrent neural network that can predict if a text sample is positive or negative.
* [Attention Basics](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/4.Recurrent-Neural-Networks/L8.Attention/attention): Will focus on implementing attention in isolation from a larger model. That's because when implementing attention in a real-world model, a lot of the focus goes into piping the data and juggling the various vectors rather than the concepts of attention themselves.

### Generative Adversarial Networks
* [Batch normalization](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/5.Generative-Adversarial-Networks/L2.Deep-Convolutional-GANs/batch-norm): Learn how to improve training rates and network stability with batch normalizations.
* [Generative Adversatial Network on MNIST](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/5.Generative-Adversarial-Networks/L1.Generative-Adversarial-Networks/gan-mnist): Train a simple generative adversarial network on the MNIST dataset.
* [Deep Convolutional GAN (DCGAN)](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/5.Generative-Adversarial-Networks/L2.Deep-Convolutional-GANs/dcgan-svhn): Implement a DCGAN to generate new images based on the Street View House Numbers (SVHN) dataset.
* [CycleGAN](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/5.Generative-Adversarial-Networks/L4.Implementing-a-CycleGAN/cycle-gan): Implement a CycleGAN that is designed to learn from unpaired and unlabeled data; use trained generators to transform images from summer to winter and vice versa.

### Deploying a model
* [Boston Housing (Batch Transform) - High Level](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/6.Deploying%20a%20Model/Tutorials/Boston%20Housing%20-%20XGBoost%20(Batch%20Transform)%20-%20High%20Level.ipynb) is the simplest notebook which introduces you to the SageMaker ecosystem and how everything works together. The data used is already clean and tabular so that no additional processing needs to be done. Uses the Batch Transform method to test the fit model.
* [Boston Housing (Batch Transform) - Low Level](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/6.Deploying%20a%20Model/Tutorials/Boston%20Housing%20-%20XGBoost%20(Batch%20Transform)%20-%20Low%20Level.ipynb) performs the same analysis as the low level notebook, instead using the low level api. As a result it is a little more verbose, however, it has the advantage of being more flexible. It is a good idea to know each of the methods even if you only use one of them.
* [Boston Housing (Deploy) - High Level](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/6.Deploying%20a%20Model/Tutorials/Boston%20Housing%20-%20XGBoost%20(Deploy)%20-%20High%20Level.ipynb) is a variation on the Batch Transform notebook of the same name. Instead of using Batch Transform to test the model, it deploys and then sends the test data to the deployed endpoint.
* [Boston Housing (Deploy) - Low Level](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/6.Deploying%20a%20Model/Tutorials/Boston%20Housing%20-%20XGBoost%20(Deploy)%20-%20Low%20Level.ipynb) is again a variant of the Batch Transform notebook above. This time using the low level api and again deploys the model and sends the test data to it rather than using the batch transform method.
* [IMDB Sentiment Analysis - XGBoost - Web App](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/6.Deploying%20a%20Model/Tutorials/IMDB%20Sentiment%20Analysis%20-%20XGBoost%20-%20Web%20App.ipynb) creates a sentiment analysis model using XGBoost and deploys the model to an endpoint. Then describes how to set up AWS Lambda and API Gateway to create a simple web app that interacts with the deployed endpoint.
* [Boston Housing (Hyperparameter Tuning) - High Level](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/6.Deploying%20a%20Model/Tutorials/Boston%20Housing%20-%20XGBoost%20(Hyperparameter%20Tuning)%20-%20High%20Level.ipynb) is an extension of the Boston Housing XGBoost model where instead of training a single model, the hyperparameter tuning functionality of SageMaker is used to train a number of different models, ultimately using the best performing model.
* [Boston Housing (Hyperparameter Tuning) - Low Level](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/6.Deploying%20a%20Model/Tutorials/Boston%20Housing%20-%20XGBoost%20(Hyperparameter%20Tuning)%20-%20Low%20Level.ipynb) is a variation of the high level hyperparameter tuning notebook, this time using the low level api to create each of the objects involved in constructing a hyperparameter tuning job.
* [Boston Housing - Updating an Endpoint](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/6.Deploying%20a%20Model/Tutorials/Boston%20Housing%20-%20Updating%20an%20Endpoint.ipynb) is another extension of the Boston Housing XGBoost model where in addition we construct a Linear model and switch a deployed endpoint between the two constructed models. In addition, we look at creating an endpoint which simulates performing an A/B test by sending some portion of the incoming inference requests to the XGBoost model and the rest to the Linear model.

### Mini-Projects
* [IMDB Sentiment Analysis - XGBoost (Batch Transform)](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/6.Deploying%20a%20Model/Mini-Projects/IMDB%20Sentiment%20Analysis%20-%20XGBoost%20(Batch%20Transform).ipynb) is a notebook that is to be completed which leads you through the steps of constructing a model using XGBoost to perform sentiment analysis on the IMDB dataset.
* [IMDB Sentiment Analysis - XGBoost (Hyperparameter Tuning)](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/6.Deploying%20a%20Model/Mini-Projects/IMDB%20Sentiment%20Analysis%20-%20XGBoost%20(Hyperparameter%20Tuning).ipynb) is a notebook that is to be completed and which leads you through the steps of constructing a sentiment analysis model using XGBoost and using SageMaker's hyperparameter tuning functionality to test a number of different hyperparameters.
* [IMDB Sentiment Analysis - XGBoost (Updating a Model)](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/6.Deploying%20a%20Model/Mini-Projects/IMDB%20Sentiment%20Analysis%20-%20XGBoost%20(Updating%20a%20Model).ipynb) is a notebook that is to be completed and which leads you through the steps of constructing a sentiment analysis model using XGBoost and then exploring what happens if something changes in the underlying distribution. After exploring a change in data over time you will construct an updated model and then update a deployed endpoint so that it makes use of the new model.

### Projects
* [Your First Neural Network](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/2.Neural-Networks/Project.Predicting-Bike-Sharing-Patterns): Implement a neural network in Numpy to predict bike rentals.
* [CNN: Dog Breed Classifier](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/3.Convolutional-Neural-Networks/Project.Dog-Breed-Classifier/project-dog-classification): Build a pipeline to process real-world, user-supplied images. Given an image of a dog, the algorithm will identify an estimate of the canineâ€™s breed. If supplied an image of a human, the code will identify the resembling dog breed.
* [Text Generation](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/4.Recurrent-Neural-Networks/Project.TV-script-generation): Train a recurrent neural network on scripts from The Simpson's (copyright Fox) to generate new scripts.
* [Face Generation](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/5.Generative-Adversarial-Networks/Project.Face-Generation): Use a DCGAN on the CelebA dataset to generate images of novel and realistic human faces.
* [Sentiment Analysis Web App](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/6.Deploying%20a%20Model/Project) is a notebook and collection of Python files to be completed. The result is a deployed RNN performing sentiment analysis on movie reviews complete with publicly accessible API and a simple web page which interacts with the deployed endpoint. This project assumes that you have some familiarity with SageMaker. Completing the XGBoost Sentiment Analysis notebook should suffice.

## Dependencies

Each directory has a `requirements.txt` describing the minimal dependencies required to run the notebooks in that directory.

### pip

To install these dependencies with pip, you can issue `pip3 install -r requirements.txt`.

### Conda Environments

You can find Conda environment files for the Deep Learning program in the `environments` folder. Note that environment files are platform dependent. Versions with `tensorflow-gpu` are labeled in the filename with "GPU".
