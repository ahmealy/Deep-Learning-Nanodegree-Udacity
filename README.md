# Deep-Learning-Nanodegree-Udacity
This Repo contains my journey taking the "Deep Learning Nanodegree" with Udacity

## Table Of Contents

### Tutorials

### Introduction to Neural Networks
* [Gradient Descent](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/2.Neural-Networks/L1.Introduction-to-neural-networks/gradient-descent): Implementing Gradient Descent.
* [Backpropagation](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/2.Neural-Networks/L1.Introduction-to-neural-networks/student-admissions): Implementing backpropagation step, scaling and one hot encoding to the data.
* [Gradient Descent with Mean Square Error](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/2.Neural-Networks/L2.Implementing-gradient-descent/gradient-descent-MeanSquareError): Implementing Gradient Descent with Mean Square Error.
* [Multilayer Perceptrons backpropagation](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/2.Neural-Networks/L2.Implementing-gradient-descent/Multilayer-Perceptrons-backpropagation): Implementing multi layer perceptrons backpropagation.
* [Sentiment Analysis with Numpy](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/2.Neural-Networks/L5.Sentiment%20Analysis/sentiment-analysis-network): [Andrew Trask](http://iamtrask.github.io/) leads you through building a sentiment analysis model, predicting if some text (films review) is positive or negative.
* [Deep Learning with PyTorch](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/2.Neural-Networks/L7.Deep-Learning-with-PyTorch/intro-to-pytorch): Introduction to deep learning with PyTorch.

### Convolutional Neural Networks
* [Convolutional Neural Networks](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/3.Convolutional-Neural-Networks/L1.Convolutional-Neural-Networks/convolutional-neural-networks): Visualize the output of layers that make up a CNN. Learn how to define and train a CNN for classifying MNIST data, a handwritten digit database that is notorious in the fields of machine and deep learning. Also, define and train a CNN for classifying images in the CIFAR10 dataset.
* [Transfer Learning (ConvNet)](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/3.Convolutional-Neural-Networks/L4.Transfer-Learning/transfer-learning). In practice, most people don't train their own large networkd on huge datasets, but use pretrained networks such as VGGnet. Here you'll use VGGnet to classify images of flowers without training a network on the images themselves.
* [Weight Intialization](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/3.Convolutional-Neural-Networks/L5.Weight-Initialization/weight-initialization): Explore how initializing network weights affects performance.
* [Autoencoders](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/3.Convolutional-Neural-Networks/L6.Auto-Encoders/autoencoder): Build models for image compression and denoising, using feed-forward and convolution networks in TensorFlow.
* [Style Transfer](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/3.Convolutional-Neural-Networks/L7.Style-Transfer/style-transfer): Use a pre-trained network to extract content and style features from an image.

### Recurrent Neural Networks
* [Intro to Recurrent Networks (Time-Series Prediction)](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/4.Recurrent-Neural-Networks/L3.Implementation-of-RNN-and-LSTM/time-series): Recurrent neural networks are able to use information about the sequence of data.
* [Intro to Recurrent Networks (Character-wise RNN)](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/4.Recurrent-Neural-Networks/L3.Implementation-of-RNN-and-LSTM/char-rnn): Recurrent neural networks are able to use information about the sequence of data, such as the sequence of characters in text.
* [Embeddings (Word2Vec)](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/4.Recurrent-Neural-Networks/L5.Embeddings-and-Word2Vec/word2vec-embeddings): Implement the Word2Vec model to find semantic representations of words for use in natural language processing.
* [Sentiment Analysis RNN](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/4.Recurrent-Neural-Networks/L6.Sentiment-Prediction-RNN/sentiment-rnn): Implement a recurrent neural network that can predict if a text sample is positive or negative.
* [Attention Basics](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/4.Recurrent-Neural-Networks/L8.Attention/attention): Will focus on implementing attention in isolation from a larger model. That's because when implementing attention in a real-world model, a lot of the focus goes into piping the data and juggling the various vectors rather than the concepts of attention themselves.

### Generative Adversarial Networks
* [Batch normalization](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/5.Generative-Adversarial-Networks/L2.Deep-Convolutional-GANs/batch-norm): Learn how to improve training rates and network stability with batch normalizations.
* [Generative Adversatial Network on MNIST](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/5.Generative-Adversarial-Networks/L1.Generative-Adversarial-Networks/gan-mnist): Train a simple generative adversarial network on the MNIST dataset.
* [Deep Convolutional GAN (DCGAN)](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/5.Generative-Adversarial-Networks/L2.Deep-Convolutional-GANs/dcgan-svhn): Implement a DCGAN to generate new images based on the Street View House Numbers (SVHN) dataset.
* [CycleGAN](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/5.Generative-Adversarial-Networks/L4.Implementing-a-CycleGAN/cycle-gan): Implement a CycleGAN that is designed to learn from unpaired and unlabeled data; use trained generators to transform images from summer to winter and vice versa.

### Projects
* [Your First Neural Network](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/2.Neural-Networks/Project.Predicting-Bike-Sharing-Patterns): Implement a neural network in Numpy to predict bike rentals.
* [CNN: Dog Breed Classifier](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/3.Convolutional-Neural-Networks/Project.Dog-Breed-Classifier/project-dog-classification): Build a pipeline to process real-world, user-supplied images. Given an image of a dog, the algorithm will identify an estimate of the canineâ€™s breed. If supplied an image of a human, the code will identify the resembling dog breed.
* [Text Generation](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/4.Recurrent-Neural-Networks/Project.TV-script-generation): Train a recurrent neural network on scripts from The Simpson's (copyright Fox) to generate new scripts.
* [Face Generation](https://github.com/ahmealy/Deep-Learning-Nanodegree-Udacity/tree/master/5.Generative-Adversarial-Networks/Project.Face-Generation): Use a DCGAN on the CelebA dataset to generate images of novel and realistic human faces.

## Dependencies

Each directory has a `requirements.txt` describing the minimal dependencies required to run the notebooks in that directory.

### pip

To install these dependencies with pip, you can issue `pip3 install -r requirements.txt`.

### Conda Environments

You can find Conda environment files for the Deep Learning program in the `environments` folder. Note that environment files are platform dependent. Versions with `tensorflow-gpu` are labeled in the filename with "GPU".
